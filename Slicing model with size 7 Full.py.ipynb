{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rangeet/anaconda3/lib/python3.7/site-packages/numpy/__init__.py\n",
      "1.15.4\n",
      "0.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This notebook will demonstrate slicing\n",
    "\n",
    "import numpy as np\n",
    "import skimage as ski\n",
    "print(np.__file__)\n",
    "print(np.__version__)\n",
    "print(ski.__version__)\n",
    "#from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "from graphviz import Graph, render\n",
    "from utils.netviz import NetViz\n",
    "from utils.mnistutil import MNISTUitl\n",
    "from utils.sliceutil import Slice\n",
    "sx = 28\n",
    "sy = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = MNISTUitl()\n",
    "viz = NetViz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rangeet/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) 60000 train samples (60000,)\n",
      "10000 test samples\n",
      "(60000,) (60000,)\n",
      "WARNING:tensorflow:From /Users/rangeet/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (Flatten)              (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "H (Dense)                    (None, 49)                38465     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                500       \n",
      "=================================================================\n",
      "Total params: 38,965\n",
      "Trainable params: 38,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /Users/rangeet/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.4517 - acc: 0.6449\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6478 - acc: 0.8412\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4741 - acc: 0.8748\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4033 - acc: 0.8903\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3661 - acc: 0.8983\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3430 - acc: 0.9032\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3268 - acc: 0.9076\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3146 - acc: 0.9100\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3051 - acc: 0.9120\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2970 - acc: 0.9142\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2900 - acc: 0.9164\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2838 - acc: 0.9183\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2780 - acc: 0.9198\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2729 - acc: 0.9213\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2678 - acc: 0.9227\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2630 - acc: 0.9241\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2587 - acc: 0.9251\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2540 - acc: 0.9264\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2495 - acc: 0.9281\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2452 - acc: 0.9293\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2407 - acc: 0.9304\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2365 - acc: 0.9319\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2319 - acc: 0.9334\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2274 - acc: 0.9349\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2233 - acc: 0.9357\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2190 - acc: 0.9368\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2150 - acc: 0.9379\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2109 - acc: 0.9392\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2070 - acc: 0.9408\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2032 - acc: 0.9422\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1997 - acc: 0.9426\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1962 - acc: 0.9441\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1929 - acc: 0.9453\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1894 - acc: 0.9462\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1860 - acc: 0.9477\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1829 - acc: 0.9480\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1799 - acc: 0.9491\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1768 - acc: 0.9497\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1743 - acc: 0.9501\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1715 - acc: 0.9513\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1688 - acc: 0.9521\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1664 - acc: 0.9524\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1640 - acc: 0.9534\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1617 - acc: 0.9539\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1594 - acc: 0.9548\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1570 - acc: 0.9557\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1552 - acc: 0.9553\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1530 - acc: 0.9566\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1510 - acc: 0.9571\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1490 - acc: 0.9573\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) 60000 train samples (60000,)\n",
      "10000 test samples\n",
      "(60000,) (60000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (Flatten)              (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "H (Dense)                    (None, 49)                38465     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                500       \n",
      "=================================================================\n",
      "Total params: 38,965\n",
      "Trainable params: 38,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1.5254 - acc: 0.6298\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7150 - acc: 0.8236\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.5171 - acc: 0.8651\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4332 - acc: 0.8831\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3887 - acc: 0.8930\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3612 - acc: 0.8988\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3423 - acc: 0.9034\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3282 - acc: 0.9067\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3168 - acc: 0.9102\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3077 - acc: 0.9120\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3000 - acc: 0.9143\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2930 - acc: 0.9162\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2867 - acc: 0.9176\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2813 - acc: 0.9191\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2760 - acc: 0.9211\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2716 - acc: 0.9220\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2672 - acc: 0.9234\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2631 - acc: 0.9244\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2588 - acc: 0.9256\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2550 - acc: 0.9268\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2513 - acc: 0.9276\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2476 - acc: 0.9289\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2436 - acc: 0.9308\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2398 - acc: 0.9311\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2362 - acc: 0.9323\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2327 - acc: 0.9335\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2295 - acc: 0.9340\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2261 - acc: 0.9357\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2229 - acc: 0.9363\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2198 - acc: 0.9371\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2167 - acc: 0.9379\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2138 - acc: 0.9388\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2111 - acc: 0.9397\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2086 - acc: 0.9408\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2060 - acc: 0.9412\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2036 - acc: 0.9414\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2010 - acc: 0.9428\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1990 - acc: 0.9432\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1964 - acc: 0.9442\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1945 - acc: 0.9450\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1924 - acc: 0.9458\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1905 - acc: 0.9458\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1887 - acc: 0.9466\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1867 - acc: 0.9469\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1850 - acc: 0.9473\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1833 - acc: 0.9479\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1817 - acc: 0.9486\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1803 - acc: 0.9491\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1786 - acc: 0.9489\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1772 - acc: 0.9496\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) 60000 train samples (60000,)\n",
      "10000 test samples\n",
      "(60000,) (60000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (Flatten)              (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "H (Dense)                    (None, 49)                38465     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                500       \n",
      "=================================================================\n",
      "Total params: 38,965\n",
      "Trainable params: 38,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1.4293 - acc: 0.6530\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.6376 - acc: 0.8387\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4684 - acc: 0.8760\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3990 - acc: 0.8912\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3625 - acc: 0.8997\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3400 - acc: 0.9041\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3244 - acc: 0.9076\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3126 - acc: 0.9108\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3030 - acc: 0.9133\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2950 - acc: 0.9153\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2881 - acc: 0.9174\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2818 - acc: 0.9193\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2760 - acc: 0.9204\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2711 - acc: 0.9218\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2663 - acc: 0.9231\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2617 - acc: 0.9244\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2574 - acc: 0.9255\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2533 - acc: 0.9270\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2495 - acc: 0.9278\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2456 - acc: 0.9292\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2416 - acc: 0.9302\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2380 - acc: 0.9317\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2342 - acc: 0.9328\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2304 - acc: 0.9338\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2271 - acc: 0.9350\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2234 - acc: 0.9363\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2201 - acc: 0.9371\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2167 - acc: 0.9375\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2130 - acc: 0.9387\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2100 - acc: 0.9398\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2065 - acc: 0.9405\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2035 - acc: 0.9409\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2004 - acc: 0.9424\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1972 - acc: 0.9426\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1944 - acc: 0.9436\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1915 - acc: 0.9451\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1887 - acc: 0.9460\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1860 - acc: 0.9459\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1835 - acc: 0.9470\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1807 - acc: 0.9476\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1783 - acc: 0.9488\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1758 - acc: 0.9493\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1734 - acc: 0.9496\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1712 - acc: 0.9502\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1688 - acc: 0.9509\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1665 - acc: 0.9524\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1643 - acc: 0.9526\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1623 - acc: 0.9532\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1605 - acc: 0.9534\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1579 - acc: 0.9542\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) 60000 train samples (60000,)\n",
      "10000 test samples\n",
      "(60000,) (60000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (Flatten)              (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "H (Dense)                    (None, 49)                38465     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                500       \n",
      "=================================================================\n",
      "Total params: 38,965\n",
      "Trainable params: 38,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 1.4852 - acc: 0.6232\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6706 - acc: 0.8366\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.4817 - acc: 0.8748\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4069 - acc: 0.8891\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3686 - acc: 0.8981\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3452 - acc: 0.9026\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3292 - acc: 0.9068\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3165 - acc: 0.9095\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3062 - acc: 0.9124\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2977 - acc: 0.9149\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2899 - acc: 0.9175\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2835 - acc: 0.9188\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2779 - acc: 0.9203: 0s - loss: 0\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2729 - acc: 0.9217\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2684 - acc: 0.9236\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2641 - acc: 0.9243\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2601 - acc: 0.9252\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2564 - acc: 0.9264\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2530 - acc: 0.9270\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2496 - acc: 0.9274\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.2465 - acc: 0.9290\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2432 - acc: 0.9296\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2400 - acc: 0.9307\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2373 - acc: 0.9318\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2343 - acc: 0.9324\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2316 - acc: 0.9337\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2289 - acc: 0.9342\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2263 - acc: 0.9348\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2238 - acc: 0.9357\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2211 - acc: 0.9365\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2189 - acc: 0.9375\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2165 - acc: 0.9383\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2140 - acc: 0.9388\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2115 - acc: 0.9393\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2093 - acc: 0.9405\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2070 - acc: 0.9407\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2044 - acc: 0.9416\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2024 - acc: 0.9425: 1s \n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2003 - acc: 0.9426\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1977 - acc: 0.9437\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1958 - acc: 0.9446\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1935 - acc: 0.9449\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1914 - acc: 0.9454\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1895 - acc: 0.9459: 0s - loss: 0\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1875 - acc: 0.9467: 0s - loss: 0.1888 - acc:\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1853 - acc: 0.9471\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1833 - acc: 0.9477\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1814 - acc: 0.9485\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1793 - acc: 0.9490: 0s - loss: 0.1\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1775 - acc: 0.9496\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) 60000 train samples (60000,)\n",
      "10000 test samples\n",
      "(60000,) (60000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (Flatten)              (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "H (Dense)                    (None, 49)                38465     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                500       \n",
      "=================================================================\n",
      "Total params: 38,965\n",
      "Trainable params: 38,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 1.5221 - acc: 0.6124\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.6828 - acc: 0.8381\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.4887 - acc: 0.8754\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.4128 - acc: 0.8897: 0s - loss: 0.4190 - a\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3745 - acc: 0.8972\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.3513 - acc: 0.9016\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3357 - acc: 0.9052: 0s - loss: 0.3357 - a\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3236 - acc: 0.9074: 1s - lo\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3142 - acc: 0.9104\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.3061 - acc: 0.9124\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2996 - acc: 0.9143: 0s - loss: 0.3005 - acc: 0.\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2938 - acc: 0.9160\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2885 - acc: 0.9170: 0s - loss: 0.28\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2839 - acc: 0.9189\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2797 - acc: 0.9202\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2756 - acc: 0.9209: 1s \n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2719 - acc: 0.9221\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2683 - acc: 0.9231\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2649 - acc: 0.9240: 1s - \n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2614 - acc: 0.9250\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2581 - acc: 0.9256\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2546 - acc: 0.9276\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2516 - acc: 0.9279: 1s\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2487 - acc: 0.9289\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2456 - acc: 0.9304\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2426 - acc: 0.9308\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.2400 - acc: 0.9315: 0s - loss: 0.2407 - acc: 0\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2372 - acc: 0.9325\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2344 - acc: 0.9333\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2317 - acc: 0.9347\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2297 - acc: 0.9347\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2273 - acc: 0.9353\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2247 - acc: 0.9361: 0s - loss: 0.2275\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2226 - acc: 0.9370\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2200 - acc: 0.9377\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2183 - acc: 0.9383\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2160 - acc: 0.9390\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2138 - acc: 0.9397: 1s - loss:\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2118 - acc: 0.9405: 1s - loss:\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.2099 - acc: 0.9413: 1s - loss: 0 - ETA: 0s - loss: 0.2086 - acc: 0.941 - ETA: 0s - loss: 0.207\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.2077 - acc: 0.9419\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2059 - acc: 0.9420\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2039 - acc: 0.9423\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2021 - acc: 0.9429: 0s - loss: 0.2021 - acc: 0.942\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2000 - acc: 0.9437: 1s -\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1982 - acc: 0.9443: 0s - loss: 0.1997 - ac\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1967 - acc: 0.9455\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1946 - acc: 0.9454\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1929 - acc: 0.9457: 0s - loss: 0.1953 -  - ETA: 0s - loss: 0.1937 - acc: 0.945\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1910 - acc: 0.9465: 0s - loss: 0.1910 - acc: 0.\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) 60000 train samples (60000,)\n",
      "10000 test samples\n",
      "(60000,) (60000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (Flatten)              (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "H (Dense)                    (None, 49)                38465     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                500       \n",
      "=================================================================\n",
      "Total params: 38,965\n",
      "Trainable params: 38,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 1.4584 - acc: 0.6804\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.6580 - acc: 0.8354\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.4834 - acc: 0.8731\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.4106 - acc: 0.8881\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.3712 - acc: 0.8974: 0s - loss: 0.3762 - acc: 0. - ETA: 0s - loss: 0.3739 - acc: 0.8\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.3464 - acc: 0.9025: 0s - loss: 0.3468 - a\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3288 - acc: 0.9066: 1s - los\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.3158 - acc: 0.9096\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3053 - acc: 0.9122\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2969 - acc: 0.9153\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2895 - acc: 0.9167\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2832 - acc: 0.9183\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2775 - acc: 0.9202\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2720 - acc: 0.9215\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2668 - acc: 0.9233\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2620 - acc: 0.9240\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2572 - acc: 0.9253\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2531 - acc: 0.9265: 0s - loss: 0.2518 - acc: 0.92 - ETA: 0s - loss: 0.2526 - acc: 0.9\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2481 - acc: 0.9284\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2438 - acc: 0.9295: 1s - loss: 0.24 - ETA: 0s - loss: 0.2439 - \n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2395 - acc: 0.9304\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2352 - acc: 0.9315: 0s - loss: 0.2318 - \n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2313 - acc: 0.9333\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2271 - acc: 0.9340\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2233 - acc: 0.9355\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2197 - acc: 0.9367\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2160 - acc: 0.9372\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.2122 - acc: 0.9386\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2087 - acc: 0.9397\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2053 - acc: 0.9412\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2021 - acc: 0.9418: 1s - loss:  - ETA: 0s - loss: 0.2023 - a\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1988 - acc: 0.9428\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1961 - acc: 0.9437\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1930 - acc: 0.9443\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1901 - acc: 0.9454\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1873 - acc: 0.9463: 1s - loss: 0.1854 - acc: 0.9 - ETA: 1s - lo\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1845 - acc: 0.9470\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1819 - acc: 0.9481\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1792 - acc: 0.9483\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1770 - acc: 0.9494\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1744 - acc: 0.9495\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1720 - acc: 0.9509: 1s - loss: 0.1700 - - ETA: 0s - loss: 0.171\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1698 - acc: 0.9508\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1675 - acc: 0.9516\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1653 - acc: 0.9524\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1632 - acc: 0.9530\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1613 - acc: 0.9536\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1591 - acc: 0.9540: 1s - l\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1571 - acc: 0.9548\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1551 - acc: 0.9553\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) 60000 train samples (60000,)\n",
      "10000 test samples\n",
      "(60000,) (60000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (Flatten)              (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "H (Dense)                    (None, 49)                38465     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                500       \n",
      "=================================================================\n",
      "Total params: 38,965\n",
      "Trainable params: 38,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 1.4293 - acc: 0.6670\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.6321 - acc: 0.8389\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.4681 - acc: 0.8740\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.4010 - acc: 0.8899\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3649 - acc: 0.8982\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3423 - acc: 0.9032\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.3264 - acc: 0.9065\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3147 - acc: 0.9096\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3052 - acc: 0.9126\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2976 - acc: 0.9143: 1s - loss: 0.2972 - ac - ETA: 0s - loss: 0.2973 \n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2906 - acc: 0.9171\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2843 - acc: 0.9184: 0s - loss: 0\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2789 - acc: 0.9197\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.2738 - acc: 0.9209\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2689 - acc: 0.9232\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2642 - acc: 0.9241: 1s - loss: 0 - ETA: 0s - loss: 0.2651 -\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2600 - acc: 0.9252\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2556 - acc: 0.9265\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2518 - acc: 0.9279\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2479 - acc: 0.9287\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2441 - acc: 0.9291\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2404 - acc: 0.9313\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.2367 - acc: 0.9324\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2331 - acc: 0.9334\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2296 - acc: 0.9341: 1s -\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2260 - acc: 0.9353: 0s - loss: 0.226\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.2229 - acc: 0.9368\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2197 - acc: 0.9377\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2167 - acc: 0.9376\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2136 - acc: 0.9389\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2106 - acc: 0.9399\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2079 - acc: 0.9405\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2052 - acc: 0.9413: 0s - loss: 0.\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2023 - acc: 0.9427\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1997 - acc: 0.9429\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1971 - acc: 0.9439\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1947 - acc: 0.9446\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1923 - acc: 0.9453\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1900 - acc: 0.9460\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1876 - acc: 0.9465: 1s -\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1854 - acc: 0.9473\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1830 - acc: 0.9480\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1808 - acc: 0.9488\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1788 - acc: 0.9494\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1766 - acc: 0.9499\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1746 - acc: 0.9506\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1726 - acc: 0.9506\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1707 - acc: 0.9510\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1687 - acc: 0.9518\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1669 - acc: 0.9527\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) 60000 train samples (60000,)\n",
      "10000 test samples\n",
      "(60000,) (60000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (Flatten)              (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "H (Dense)                    (None, 49)                38465     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                500       \n",
      "=================================================================\n",
      "Total params: 38,965\n",
      "Trainable params: 38,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 1.4537 - acc: 0.6447\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.6640 - acc: 0.8336\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.4875 - acc: 0.8719\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4132 - acc: 0.8884\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3732 - acc: 0.8964\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3483 - acc: 0.9024\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3315 - acc: 0.9061\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3184 - acc: 0.9096\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3083 - acc: 0.9122\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2998 - acc: 0.9142\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2922 - acc: 0.9165\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2856 - acc: 0.9174\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2797 - acc: 0.9187: 1s - loss:\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2739 - acc: 0.9205\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2686 - acc: 0.9224\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2635 - acc: 0.9238: 1s - loss: 0\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2583 - acc: 0.9254\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2539 - acc: 0.9273\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2493 - acc: 0.9285\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2448 - acc: 0.9295\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2407 - acc: 0.9304\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2365 - acc: 0.9320\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2326 - acc: 0.9331\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2287 - acc: 0.9346\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2249 - acc: 0.9358\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2211 - acc: 0.9363\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.2173 - acc: 0.9378\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.2139 - acc: 0.9388\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2101 - acc: 0.9400\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2066 - acc: 0.9414\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.2033 - acc: 0.9425\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1999 - acc: 0.9438\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1966 - acc: 0.9448\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1934 - acc: 0.9453\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.1905 - acc: 0.9458\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1871 - acc: 0.9470\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1845 - acc: 0.9476\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.1817 - acc: 0.9485\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1790 - acc: 0.9499\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1763 - acc: 0.9505\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1737 - acc: 0.9511\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1713 - acc: 0.9516\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1685 - acc: 0.9525\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1666 - acc: 0.9527\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.1643 - acc: 0.9535\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1620 - acc: 0.9546\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.1600 - acc: 0.9547\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1579 - acc: 0.9551\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1560 - acc: 0.9560\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.1540 - acc: 0.9564\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) 60000 train samples (60000,)\n",
      "10000 test samples\n",
      "(60000,) (60000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (Flatten)              (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "H (Dense)                    (None, 49)                38465     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                500       \n",
      "=================================================================\n",
      "Total params: 38,965\n",
      "Trainable params: 38,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 1.4531 - acc: 0.6392\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.6690 - acc: 0.8370\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.4840 - acc: 0.8751: 0s - loss:\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.4085 - acc: 0.8902: 0s - loss: 0.4141 -\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3694 - acc: 0.8985: 0s - loss: 0.3694 - acc: 0\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3445 - acc: 0.9039\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3271 - acc: 0.9077: \n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3138 - acc: 0.9106\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3034 - acc: 0.9134\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2944 - acc: 0.9162\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2870 - acc: 0.9177\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2803 - acc: 0.9198\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2740 - acc: 0.9211\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2685 - acc: 0.9225\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2630 - acc: 0.9243: 0s - loss: 0\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2579 - acc: 0.9260: 0s - loss: 0.2577 \n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2528 - acc: 0.9272\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2483 - acc: 0.9282\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2438 - acc: 0.9293\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2393 - acc: 0.9315\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2349 - acc: 0.9333\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2307 - acc: 0.9339\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2266 - acc: 0.9359\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2225 - acc: 0.9361\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2189 - acc: 0.9379: 1s - l\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2154 - acc: 0.9388\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2117 - acc: 0.9405: 1s -\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2083 - acc: 0.9412: 0s - loss: 0.2074 - acc: 0\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2050 - acc: 0.9421: 0s - loss: 0.2050 - acc: 0.941 - ETA: 0s - loss: 0.2064 - a\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2018 - acc: 0.9429\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1987 - acc: 0.9436\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1958 - acc: 0.9450: 0s - loss: 0.1963 - acc: 0\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1929 - acc: 0.9457: 1s - loss: 0\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1899 - acc: 0.9465: 0s - loss: 0.1905 - \n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1873 - acc: 0.9471\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1847 - acc: 0.9479: 0s - loss: 0.1845 - ac\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1823 - acc: 0.9484\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1797 - acc: 0.9489\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1775 - acc: 0.9501\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1750 - acc: 0.9506\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1729 - acc: 0.9509\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1708 - acc: 0.9519\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1687 - acc: 0.9523\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1668 - acc: 0.9524: 1s - loss: 0. - ETA: 0s - loss: 0.1677 \n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1647 - acc: 0.9535\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1626 - acc: 0.9540\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1608 - acc: 0.9546: 1s - loss: 0.162 - ETA: 0s - loss: 0.1628 - a\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1589 - acc: 0.9550\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1571 - acc: 0.9556\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1555 - acc: 0.9563\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) 60000 train samples (60000,)\n",
      "10000 test samples\n",
      "(60000,) (60000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (Flatten)              (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "H (Dense)                    (None, 49)                38465     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                500       \n",
      "=================================================================\n",
      "Total params: 38,965\n",
      "Trainable params: 38,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 1.4303 - acc: 0.6633\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.6334 - acc: 0.8423\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.4658 - acc: 0.8766\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3981 - acc: 0.8923\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3629 - acc: 0.8996\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3408 - acc: 0.9045\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3258 - acc: 0.9076\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3143 - acc: 0.9102\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3051 - acc: 0.9122\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2973 - acc: 0.9147\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2903 - acc: 0.9165\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2842 - acc: 0.9176\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2787 - acc: 0.9193\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2738 - acc: 0.9209\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2689 - acc: 0.9226\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2646 - acc: 0.9235\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2600 - acc: 0.9251\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2555 - acc: 0.9265\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2514 - acc: 0.9273\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2474 - acc: 0.9285\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2434 - acc: 0.9297\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2396 - acc: 0.9307\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2359 - acc: 0.9322\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2320 - acc: 0.9336\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2288 - acc: 0.9345\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2252 - acc: 0.9353\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2216 - acc: 0.9365\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2181 - acc: 0.9376\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2145 - acc: 0.9387\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2112 - acc: 0.9400\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.2076 - acc: 0.9410\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.2041 - acc: 0.9423\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.2005 - acc: 0.9429\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1971 - acc: 0.9435\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1938 - acc: 0.9446: 0s - loss: \n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1904 - acc: 0.9452\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1873 - acc: 0.9462\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1841 - acc: 0.9477\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1811 - acc: 0.9481\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1779 - acc: 0.9491\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1747 - acc: 0.9505\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1721 - acc: 0.9510\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1691 - acc: 0.9517\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1664 - acc: 0.9531\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1639 - acc: 0.9537\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1613 - acc: 0.9541\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1586 - acc: 0.9546\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1562 - acc: 0.9554\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1541 - acc: 0.9562\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.1517 - acc: 0.9569\n"
     ]
    }
   ],
   "source": [
    "X, Y, x, y = mn.getdata2(0,0,sx,sy)\n",
    "na , xt, yt = mn.train2(X, Y, x,y,sx,sy,10,50)\n",
    "nb , xt1, yt1 = mn.train2(X, Y, x,y,sx,sy,10,50)\n",
    "nc , xt, yt = mn.train2(X, Y, x,y,sx,sy,10,50)\n",
    "nd , xt1, yt1 = mn.train2(X, Y, x,y,sx,sy,10,50)\n",
    "ne , xt, yt = mn.train2(X, Y, x,y,sx,sy,10,50)\n",
    "nf , xt1, yt1 = mn.train2(X, Y, x,y,sx,sy,10,50)\n",
    "ng , xt, yt = mn.train2(X, Y, x,y,sx,sy,10,50)\n",
    "nh , xt1, yt1 = mn.train2(X, Y, x,y,sx,sy,10,50)\n",
    "ni , xt, yt = mn.train2(X, Y, x,y,sx,sy,10,50)\n",
    "nj , xt1, yt1 = mn.train2(X, Y, x,y,sx,sy,10,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya  = []\n",
    "yb = []\n",
    "yc  = []\n",
    "yd = []\n",
    "ye  = []\n",
    "yf = []\n",
    "yg  = []\n",
    "yh = []\n",
    "yi  = []\n",
    "yj = []\n",
    "slca = Slice()\n",
    "slcb = Slice()\n",
    "slcc = Slice()\n",
    "slcd = Slice()\n",
    "slce = Slice()\n",
    "slcf = Slice()\n",
    "slcg = Slice()\n",
    "slch = Slice()\n",
    "slci = Slice()\n",
    "slcj = Slice()\n",
    "aW1, aW2, ab1, ab2 = slca.getweights(na)\n",
    "bW1, bW2, bb1, bb2 = slcb.getweights(nb)\n",
    "cW1, cW2, cb1, cb2 = slcc.getweights(nc)\n",
    "dW1, dW2, db1, db2 = slcd.getweights(nd)\n",
    "eW1, eW2, eb1, eb2 = slce.getweights(ne)\n",
    "fW1, fW2, fb1, fb2 = slcf.getweights(nf)\n",
    "gW1, gW2, gb1, gb2 = slcg.getweights(ng)\n",
    "hW1, hW2, hb1, hb2 = slch.getweights(nh)\n",
    "iW1, iW2, ib1, ib2 = slci.getweights(ni)\n",
    "jW1, jW2, ib1, jb2 = slcj.getweights(nj)\n",
    "la = 0\n",
    "lb = 1\n",
    "lc = 2\n",
    "ld = 3\n",
    "le = 4\n",
    "lf = 5\n",
    "lg = 6\n",
    "lh = 7\n",
    "li = 8\n",
    "lj = 9\n",
    "th1 = .001\n",
    "th2 = .001\n",
    "for i in range(0,len(yt)):\n",
    "    if yt[i] == la and na.predict(xt[i:i+1])[0][la] >.9:\n",
    "        ya.append(xt[i])\n",
    "    if yt[i] == lb and nb.predict(xt[i:i+1])[0][lb] >.9:\n",
    "        yb.append(xt[i])\n",
    "    if yt[i] == lc and nc.predict(xt[i:i+1])[0][lc] >.9:\n",
    "        yc.append(xt[i])\n",
    "    if yt[i] == ld and nd.predict(xt[i:i+1])[0][ld] >.9:\n",
    "        yd.append(xt[i])\n",
    "    if yt[i] == le and ne.predict(xt[i:i+1])[0][le] >.9:\n",
    "        ye.append(xt[i])\n",
    "    if yt[i] == lf and nf.predict(xt[i:i+1])[0][lf] >.9:\n",
    "        yf.append(xt[i])\n",
    "    if yt[i] == lg and ng.predict(xt[i:i+1])[0][lg] >.9:\n",
    "        yg.append(xt[i])\n",
    "    if yt[i] == lh and nh.predict(xt[i:i+1])[0][lh] >.9:\n",
    "        yh.append(xt[i])\n",
    "    if yt[i] == li and ni.predict(xt[i:i+1])[0][li] >.9:\n",
    "        yi.append(xt[i])\n",
    "    if yt[i] == lj and nj.predict(xt[i:i+1])[0][lj] >.9:\n",
    "        yj.append(xt[i])\n",
    "print(len(ya),len(yb),len(yc),len(yd),len(ye),len(yf),len(yg),len(yh),len(yi),len(yj))\n",
    "\n",
    "np.random.shuffle(ya)\n",
    "np.random.shuffle(yb)\n",
    "np.random.shuffle(yc)\n",
    "np.random.shuffle(yd)\n",
    "np.random.shuffle(ye)\n",
    "np.random.shuffle(yf)\n",
    "np.random.shuffle(yg)\n",
    "np.random.shuffle(yh)\n",
    "np.random.shuffle(yi)\n",
    "np.random.shuffle(yj)\n",
    "ya = ya[0:100]\n",
    "yb = yb[0:100]\n",
    "yc = yc[0:100]\n",
    "yd = yd[0:100]\n",
    "ye = ye[0:100]\n",
    "yf = yf[0:100]\n",
    "yg = yg[0:100]\n",
    "yh = yh[0:100]\n",
    "yi = yi[0:100]\n",
    "yj = yj[0:100]\n",
    "#slc.D1\n",
    "\n",
    "ac = 0\n",
    "for x in ya:\n",
    "    #W1, W2,b1,b2 = slc.dynamicmodify(nm,x,sx,sy)\n",
    "    aW1, aW2,ab1,ab2 = slca.modifyThroughInterSection(na,x,sx,sy, th1)\n",
    "    ac = ac + 1\n",
    "    #print(np.count_nonzero(slcm.D2))\n",
    "    if np.count_nonzero(slca.D2) < 45:\n",
    "        print(\"Breaking at ac \", ac,np.count_nonzero(slca.D2))\n",
    "        slca.first = True\n",
    "\n",
    "bc = 0\n",
    "for x in yb:\n",
    "    #W1, W2,b1,b2 = slc.dynamicmodify(nm,x,sx,sy)\n",
    "    bW1, bW2,bb1,bb2 = slcb.modifyThroughInterSection(nb,x,sx,sy, th2)\n",
    "    bc = bc + 1\n",
    "    if np.count_nonzero(slcb.D2) < 45:\n",
    "        print(\"Breaking at bc \", bc,np.count_nonzero(slcb.D2))\n",
    "        slcb.first = True\n",
    "cc = 0\n",
    "for x in yc:\n",
    "    #W1, W2,b1,b2 = slc.dynamicmodify(nm,x,sx,sy)\n",
    "    cW1, cW2,cb1,cb2 = slcc.modifyThroughInterSection(nc,x,sx,sy, th1)\n",
    "    cc = cc + 1\n",
    "    #print(np.count_nonzero(slcm.D2))\n",
    "    if np.count_nonzero(slcc.D2) < 45:\n",
    "        print(\"Breaking at cc \", cc,np.count_nonzero(slcc.D2))\n",
    "        slcc.first = True\n",
    "\n",
    "dc = 0\n",
    "for x in yd:\n",
    "    #W1, W2,b1,b2 = slc.dynamicmodify(nm,x,sx,sy)\n",
    "    dW1, dW2,db1,db2 = slcd.modifyThroughInterSection(nd,x,sx,sy, th2)\n",
    "    dc = dc + 1\n",
    "    if np.count_nonzero(slcd.D2) < 45:\n",
    "        print(\"Breaking at dc \", dc,np.count_nonzero(slcd.D2))\n",
    "        slcd.first = True\n",
    "        \n",
    "ec = 0\n",
    "for x in ye:\n",
    "    #W1, W2,b1,b2 = slc.dynamicmodify(nm,x,sx,sy)\n",
    "    eW1, eW2,eb1,eb2 = slce.modifyThroughInterSection(ne,x,sx,sy, th1)\n",
    "    ec = ec + 1\n",
    "    #print(np.count_nonzero(slcm.D2))\n",
    "    if np.count_nonzero(slce.D2) < 45:\n",
    "        print(\"Breaking at ec \", ec,np.count_nonzero(slce.D2))\n",
    "        slce.first = True\n",
    "\n",
    "fc = 0\n",
    "for x in yf:\n",
    "    #W1, W2,b1,b2 = slc.dynamicmodify(nm,x,sx,sy)\n",
    "    fW1, fW2,fb1,fb2 = slcf.modifyThroughInterSection(nf,x,sx,sy, th2)\n",
    "    fc = fc + 1\n",
    "    if np.count_nonzero(slcf.D2) < 45:\n",
    "        print(\"Breaking at fc \", fc,np.count_nonzero(slcf.D2))\n",
    "        slcf.first = True\n",
    "        \n",
    "gc = 0\n",
    "for x in yg:\n",
    "    #W1, W2,b1,b2 = slc.dynamicmodify(nm,x,sx,sy)\n",
    "    gW1, gW2,gb1,gb2 = slcg.modifyThroughInterSection(ng,x,sx,sy, th1)\n",
    "    gc = gc + 1\n",
    "    #print(np.count_nonzero(slcm.D2))\n",
    "    if np.count_nonzero(slcg.D2) < 45:\n",
    "        print(\"Breaking at gc \", gc,np.count_nonzero(slcg.D2))\n",
    "        slcg.first = True\n",
    "\n",
    "hc = 0\n",
    "for x in yh:\n",
    "    #W1, W2,b1,b2 = slc.dynamicmodify(nm,x,sx,sy)\n",
    "    hW1, hW2,hb1,hb2 = slch.modifyThroughInterSection(nh,x,sx,sy, th2)\n",
    "    hc = hc + 1\n",
    "    if np.count_nonzero(slch.D2) < 45:\n",
    "        print(\"Breaking at hc \", hc,np.count_nonzero(slch.D2))\n",
    "        slch.first = True\n",
    "ic = 0\n",
    "for x in yi:\n",
    "    #W1, W2,b1,b2 = slc.dynamicmodify(nm,x,sx,sy)\n",
    "    iW1, iW2,ib1,ib2 = slci.modifyThroughInterSection(ni,x,sx,sy, th1)\n",
    "    ic = ic + 1\n",
    "    #print(np.count_nonzero(slcm.D2))\n",
    "    if np.count_nonzero(slci.D2) < 45:\n",
    "        print(\"Breaking at ic \", ic,np.count_nonzero(slci.D2))\n",
    "        slci.first = True\n",
    "\n",
    "jc = 0\n",
    "for x in yj:\n",
    "    #W1, W2,b1,b2 = slc.dynamicmodify(nm,x,sx,sy)\n",
    "    jW1, jW2,jb1,jb2 = slcj.modifyThroughInterSection(nj,x,sx,sy, th2)\n",
    "    jc = jc + 1\n",
    "    if np.count_nonzero(slcj.D2) < 45:\n",
    "        print(\"Breaking at jc \", jc,np.count_nonzero(slcj.D2))\n",
    "        slcj.first = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0\n",
    "na.layers[1].set_weights([slca.D1,slca.d1])\n",
    "na.layers[2].set_weights([slca.D2,slca.d2])\n",
    "#print(model.get_weights())\n",
    "from sklearn.metrics import accuracy_score\n",
    "zeros = []\n",
    "pred = []\n",
    "tr = []\n",
    "labs = [0,1,2,3,4,5,6,7,8,9]\n",
    "acc = []\n",
    "count = 0\n",
    "for ly in labs:\n",
    "    pred = []\n",
    "    tr = []\n",
    "    for i in range(0,len(yt)):\n",
    "        count += 1\n",
    "        if yt[i] == ly:\n",
    "            p = na.predict(xt[i:i+1])\n",
    "            m = p.argmax()\n",
    "            pred.append(m)\n",
    "            tr.append(ly)\n",
    "    score = accuracy_score(pred,tr)\n",
    "    acc.append(score)\n",
    "print(acc)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "nb.layers[1].set_weights([slcb.D1,slcb.d1])\n",
    "nb.layers[2].set_weights([slcb.D2,slcb.d2])\n",
    "#print(model.get_weights())\n",
    "from sklearn.metrics import accuracy_score\n",
    "zeros = []\n",
    "pred = []\n",
    "tr = []\n",
    "labs = [0,1,2,3,4,5,6,7,8,9]\n",
    "acc = []\n",
    "count = 0\n",
    "for ly in labs:\n",
    "    pred = []\n",
    "    tr = []\n",
    "    for i in range(0,len(yt)):\n",
    "        count += 1\n",
    "        if yt[i] == ly:\n",
    "            p = nb.predict(xt[i:i+1])\n",
    "            m = p.argmax()\n",
    "            pred.append(m)\n",
    "            tr.append(ly)\n",
    "    score = accuracy_score(pred,tr)\n",
    "    acc.append(score)\n",
    "print(acc)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "nc.layers[1].set_weights([slcc.D1,slcc.d1])\n",
    "nc.layers[2].set_weights([slcc.D2,slcc.d2])\n",
    "#print(model.get_weights())\n",
    "from sklearn.metrics import accuracy_score\n",
    "zeros = []\n",
    "pred = []\n",
    "tr = []\n",
    "labs = [0,1,2,3,4,5,6,7,8,9]\n",
    "acc = []\n",
    "count = 0\n",
    "for ly in labs:\n",
    "    pred = []\n",
    "    tr = []\n",
    "    for i in range(0,len(yt)):\n",
    "        count += 1\n",
    "        if yt[i] == ly:\n",
    "            p = nc.predict(xt[i:i+1])\n",
    "            m = p.argmax()\n",
    "            pred.append(m)\n",
    "            tr.append(ly)\n",
    "    score = accuracy_score(pred,tr)\n",
    "    acc.append(score)\n",
    "print(acc)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "nd.layers[1].set_weights([slcd.D1,slcd.d1])\n",
    "nd.layers[2].set_weights([slcd.D2,slcd.d2])\n",
    "#print(model.get_weights())\n",
    "from sklearn.metrics import accuracy_score\n",
    "zeros = []\n",
    "pred = []\n",
    "tr = []\n",
    "labs = [0,1,2,3,4,5,6,7,8,9]\n",
    "acc = []\n",
    "count = 0\n",
    "for ly in labs:\n",
    "    pred = []\n",
    "    tr = []\n",
    "    for i in range(0,len(yt)):\n",
    "        count += 1\n",
    "        if yt[i] == ly:\n",
    "            p = nd.predict(xt[i:i+1])\n",
    "            m = p.argmax()\n",
    "            pred.append(m)\n",
    "            tr.append(ly)\n",
    "    score = accuracy_score(pred,tr)\n",
    "    acc.append(score)\n",
    "print(acc)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "ne.layers[1].set_weights([slce.D1,slce.d1])\n",
    "ne.layers[2].set_weights([slce.D2,slce.d2])\n",
    "#print(model.get_weights())\n",
    "from sklearn.metrics import accuracy_score\n",
    "zeros = []\n",
    "pred = []\n",
    "tr = []\n",
    "labs = [0,1,2,3,4,5,6,7,8,9]\n",
    "acc = []\n",
    "count = 0\n",
    "for ly in labs:\n",
    "    pred = []\n",
    "    tr = []\n",
    "    for i in range(0,len(yt)):\n",
    "        count += 1\n",
    "        if yt[i] == ly:\n",
    "            p = ne.predict(xt[i:i+1])\n",
    "            m = p.argmax()\n",
    "            pred.append(m)\n",
    "            tr.append(ly)\n",
    "    score = accuracy_score(pred,tr)\n",
    "    acc.append(score)\n",
    "print(acc)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "nf.layers[1].set_weights([slcf.D1,slcf.d1])\n",
    "nf.layers[2].set_weights([slcf.D2,slcf.d2])\n",
    "#print(model.get_weights())\n",
    "from sklearn.metrics import accuracy_score\n",
    "zeros = []\n",
    "pred = []\n",
    "tr = []\n",
    "labs = [0,1,2,3,4,5,6,7,8,9]\n",
    "acc = []\n",
    "count = 0\n",
    "for ly in labs:\n",
    "    pred = []\n",
    "    tr = []\n",
    "    for i in range(0,len(yt)):\n",
    "        count += 1\n",
    "        if yt[i] == ly:\n",
    "            p = nf.predict(xt[i:i+1])\n",
    "            m = p.argmax()\n",
    "            pred.append(m)\n",
    "            tr.append(ly)\n",
    "    score = accuracy_score(pred,tr)\n",
    "    acc.append(score)\n",
    "print(acc)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "ng.layers[1].set_weights([slcg.D1,slcg.d1])\n",
    "ng.layers[2].set_weights([slcg.D2,slcg.d2])\n",
    "#print(model.get_weights())\n",
    "from sklearn.metrics import accuracy_score\n",
    "zeros = []\n",
    "pred = []\n",
    "tr = []\n",
    "labs = [0,1,2,3,4,5,6,7,8,9]\n",
    "acc = []\n",
    "count = 0\n",
    "for ly in labs:\n",
    "    pred = []\n",
    "    tr = []\n",
    "    for i in range(0,len(yt)):\n",
    "        count += 1\n",
    "        if yt[i] == ly:\n",
    "            p = ng.predict(xt[i:i+1])\n",
    "            m = p.argmax()\n",
    "            pred.append(m)\n",
    "            tr.append(ly)\n",
    "    score = accuracy_score(pred,tr)\n",
    "    acc.append(score)\n",
    "print(acc)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "nh.layers[1].set_weights([slch.D1,slch.d1])\n",
    "nh.layers[2].set_weights([slch.D2,slch.d2])\n",
    "#print(model.get_weights())\n",
    "from sklearn.metrics import accuracy_score\n",
    "zeros = []\n",
    "pred = []\n",
    "tr = []\n",
    "labs = [0,1,2,3,4,5,6,7,8,9]\n",
    "acc = []\n",
    "count = 0\n",
    "for ly in labs:\n",
    "    pred = []\n",
    "    tr = []\n",
    "    for i in range(0,len(yt)):\n",
    "        count += 1\n",
    "        if yt[i] == ly:\n",
    "            p = nh.predict(xt[i:i+1])\n",
    "            m = p.argmax()\n",
    "            pred.append(m)\n",
    "            tr.append(ly)\n",
    "    score = accuracy_score(pred,tr)\n",
    "    acc.append(score)\n",
    "print(acc)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "ni.layers[1].set_weights([slci.D1,slci.d1])\n",
    "ni.layers[2].set_weights([slci.D2,slci.d2])\n",
    "#print(model.get_weights())\n",
    "from sklearn.metrics import accuracy_score\n",
    "zeros = []\n",
    "pred = []\n",
    "tr = []\n",
    "labs = [0,1,2,3,4,5,6,7,8,9]\n",
    "acc = []\n",
    "count = 0\n",
    "for ly in labs:\n",
    "    pred = []\n",
    "    tr = []\n",
    "    for i in range(0,len(yt)):\n",
    "        count += 1\n",
    "        if yt[i] == ly:\n",
    "            p = ni.predict(xt[i:i+1])\n",
    "            m = p.argmax()\n",
    "            pred.append(m)\n",
    "            tr.append(ly)\n",
    "    score = accuracy_score(pred,tr)\n",
    "    acc.append(score)\n",
    "print(acc)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "nj.layers[1].set_weights([slcj.D1,slcj.d1])\n",
    "nj.layers[2].set_weights([slcj.D2,slcj.d2])\n",
    "#print(model.get_weights())\n",
    "from sklearn.metrics import accuracy_score\n",
    "zeros = []\n",
    "pred = []\n",
    "tr = []\n",
    "labs = [0,1,2,3,4,5,6,7,8,9]\n",
    "acc = []\n",
    "count = 0\n",
    "for ly in labs:\n",
    "    pred = []\n",
    "    tr = []\n",
    "    for i in range(0,len(yt)):\n",
    "        count += 1\n",
    "        if yt[i] == ly:\n",
    "            p = nj.predict(xt[i:i+1])\n",
    "            m = p.argmax()\n",
    "            pred.append(m)\n",
    "            tr.append(ly)\n",
    "    score = accuracy_score(pred,tr)\n",
    "    acc.append(score)\n",
    "print(acc)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].set_weights([slcm.D1,slcm.d1])\n",
    "model.layers[2].set_weights([slcm.D2,slcm.d2])\n",
    "\n",
    "\n",
    "\n",
    "model2.layers[1].set_weights([slcn.D1,slcn.d1])\n",
    "model2.layers[2].set_weights([slcn.D2,slcn.d2])\n",
    "\n",
    "\n",
    "w1, b1, w2, b2 = slcm.joinModules(model,model2)\n",
    "model.layers[1].set_weights([w1,b1])\n",
    "model.layers[2].set_weights([w2,b2])\n",
    "from sklearn.metrics import accuracy_score\n",
    "zeros = []\n",
    "pred = []\n",
    "tr = []\n",
    "labs = [0,1,2,3,4,5,6,7,8,9]\n",
    "acc = []\n",
    "count = 0\n",
    "for ly in labs:\n",
    "    pred = []\n",
    "    tr = []\n",
    "    for i in range(0,len(yt)):\n",
    "        count += 1\n",
    "        if yt[i] == l:\n",
    "            p = model.predict(xt[i:i+1])\n",
    "            m = p.argmax()\n",
    "            pred.append(m)\n",
    "            tr.append(ly)\n",
    "    score = accuracy_score(pred,tr)\n",
    "    acc.append(score)\n",
    "print(acc)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doto, A = viz.vispredictwights(model, xt[1], yt[1] , sx, sy )\n",
    "#dot, A, g = viz.vispredict(model, xt[0], [7],sx,sy,ss = .02)\n",
    "\n",
    "#doto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(l)\n",
    "#dot.render('img/intersect/{0}/ma.gv'.format(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 61\n",
    "t = 62\n",
    "print(yt[s:t])\n",
    "model.predict(xt[s:t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slc.D1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import conv2d as cnv\n",
    "W1 = slc.D1.reshape((784 ,49 ,1,1))\n",
    "print(W1.shape, W1.shape[:2],xt[0:1].shape)\n",
    "M1 = cnv.conv2d(xt[0:1],W1, stride=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(slc.D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
